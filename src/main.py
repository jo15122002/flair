import json
import logging

from comment_publisher import post_comments
from config import load_config
from diff_extractor import (filter_diff, get_diff_from_pr,
                            preprocess_diff_with_line_numbers,
                            split_diff_intelligent)
from llm_client import (adjust_line_number_from_diff, build_llm_prompt,
                        extract_json_from_text, query_llm)


def main():
    # Load configuration and initialize logging
    config = load_config()
    if not config:
        logging.error("Error loading configuration.")
        return
    logging.basicConfig(level=logging.INFO)
    
    # 1. Retrieve diff via GitHub API
    logging.info("Retrieving diff for the pull request via GitHub API...")
    diff = get_diff_from_pr()
    if not diff:
        logging.error("No diff retrieved. Check environment variables and permissions.")
        return
    
    # Preprocess diff to add line numbers for clarity
    diff_with_line_numbers = preprocess_diff_with_line_numbers(diff)
    logging.info("Diff preprocessed with line numbers.")
    
    # Filter diff to exclude test files and other unwanted patterns
    diff_filtered = filter_diff(diff_with_line_numbers, exclude_patterns=config.EXCLUDE_PATTERNS)
    
    # 2. Intelligently split diff into chunks (by file block or by number of lines)
    chunks = split_diff_intelligent(diff_filtered, max_lines=1000)
    logging.info("Diff split into %d chunk(s).", len(chunks))
    
    all_comments = []
    
    logging.info("Using gitingest: %s", config.USE_GITINGEST)
    
    # 3. For each chunk, query the LLM
    for i, chunk in enumerate(chunks):
        logging.info("Sending chunk %d/%d to the LLM...", i+1, len(chunks))
        response = query_llm(chunk, config)
        if response is None:
            logging.error("Error receiving LLM response for chunk %d.", i+1)
            continue
        
        response_content = response.get("content")
        if response_content is None:
            logging.error("LLM response for chunk %d is empty or malformed.", i+1)
            continue
        
        parsed_response = extract_json_from_text(response_content)
        if parsed_response is None:
            logging.error("Unable to extract JSON from chunk %d.", i+1)
            comments = []
        else:
            comments = parsed_response.get("comments", [])
        
        # Uncomment the following block if you wish to adjust reported line numbers:
        # for comment in comments:
        #     reported_line = comment.get("line")
        #     try:
        #         reported_line_int = int(reported_line)
        #     except (ValueError, TypeError):
        #         logging.warning("Invalid line number for comment: %s", reported_line)
        #         continue
        #     adjusted_line = adjust_line_number_from_diff(chunk, reported_line_int)
        #     comment["line"] = adjusted_line
        
        if comments:
            logging.info("Chunk %d processed: %d comment(s) generated.", i+1, len(comments))
            all_comments.extend(comments)
        else:
            logging.info("No comments generated for chunk %d.", i+1)

    if not all_comments:
        logging.info("No comments generated by the LLM across the diff.")
        return

    # 4. Publish comments on the pull request
    logging.info("Publishing comments on the pull request...")
    if post_comments(all_comments):
        logging.info("Comments published successfully.")
    else:
        logging.error("Error publishing comments.")

if __name__ == "__main__":
    main()
